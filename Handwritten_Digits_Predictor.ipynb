{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZK0UPEy5RYK+5huyXeGp/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishaann1202/LibraryManagementSystemOriginal.java/blob/master/Handwritten_Digits_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8U1BVwa_SZON"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")"
      ],
      "metadata": {
        "id": "m5ke6ZCZTk7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149f8943-9eb4-4e4c-93ea-beec4cd3a44f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 343kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.19MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.14MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD8jCyv37qCz",
        "outputId": "f91f855b-2cdc-4ffb-b9ac-e5c02c0f9325"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIx96EcL7rir",
        "outputId": "056fba6e-1294-46a6-e42f-5c5b19157517"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNt4uRnl8dl1",
        "outputId": "4b5f5aa7-75a1-4027-e5cc-492780d12735"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmUsY4XVAEnn",
        "outputId": "69a53d83-e3bc-47cf-95f2-48c7d2a9452d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GpBnGJ_AJMU",
        "outputId": "d3dfb753-dab1-4a7f-9adc-78cb4f6414fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeXI9EW8FAr3",
        "outputId": "d7a5d9f2-036a-4ace-8dd8-3693462f8482"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "GKdKrrpHFFQt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "\n",
        "    'test': DataLoader(test_data,\n",
        "                       batch_size=100,\n",
        "                       shuffle=True,\n",
        "                       num_workers=1),\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "fqZRzV_JFTNO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpqECwBmHsrY",
        "outputId": "25765da5-6694-44a7-9496-c10106a95b4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7bfbc5f2aa90>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7bfbc5ef9410>}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
        "        self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
        "        self.conv2_drop=nn.Dropout2d()\n",
        "        self.fc1=nn.Linear(320,50)\n",
        "        self.fc2=nn.Linear(50,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "        x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
        "        x=x.view(-1,320)\n",
        "        x=F.relu(self.fc1(x))\n",
        "        x=F.dropout(x,training=self.training)\n",
        "        x=self.fc2(x)\n",
        "        return F.softmax(x)\n"
      ],
      "metadata": {
        "id": "xH91oC8wIew6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
        "                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'])\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
        "          f'({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
        "\n",
        "# Run training and testing loop\n",
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "metadata": {
        "id": "p_YUtSrMVxsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f92d5e-7c88-456d-8e4e-787ca164eec3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-9930ebfac668>:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302597\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.301283\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.234672\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.971412\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.879589\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.844073\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.822018\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.796270\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.820281\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.689098\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.784233\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.715759\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.733704\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.699518\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.691168\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.732498\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.686617\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.687722\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.675147\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.686683\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.681206\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.578352\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.614863\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.592383\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.634450\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.668624\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.652923\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.651140\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.579866\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.623315\n",
            "\n",
            "Test set: Average loss: 1.5358, Accuracy: 9280/10000 (93%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.608978\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.638286\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.577374\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.577634\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.578293\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.578491\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.631011\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.648229\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.626075\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.565289\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.608139\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.571177\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.593335\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.546323\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.574349\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.601174\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.550769\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.612534\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.556561\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.568715\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.552877\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.587750\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.527243\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.606596\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.587368\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.577529\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.573433\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.590104\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.546737\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.631795\n",
            "\n",
            "Test set: Average loss: 1.5158, Accuracy: 9460/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.566073\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.566746\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.565259\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.607156\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.610355\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.564879\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.563090\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.599626\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.637319\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.587711\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.624411\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.653603\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.548640\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.570470\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.568079\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.587889\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.580010\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.541521\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.521202\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.544409\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.530265\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.621033\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.554365\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.536811\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.533713\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.628203\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.577467\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.576606\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.634390\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.588291\n",
            "\n",
            "Test set: Average loss: 1.5094, Accuracy: 9519/10000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.527072\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.537787\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.549393\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.540008\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.573527\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.582516\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.564541\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.635877\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.545557\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.553843\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.572199\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.608940\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.549211\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.545959\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.560228\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.581237\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.565444\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.542263\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.574312\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.587231\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.574620\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.585942\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.555454\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.548621\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.526854\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.521467\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.535507\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.558962\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.549353\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.542702\n",
            "\n",
            "Test set: Average loss: 1.5014, Accuracy: 9603/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.544105\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.569916\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.637399\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.572824\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.519959\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.508006\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.558321\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.594462\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.571365\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.535695\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.565684\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.566921\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.583558\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.560986\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.535647\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.591679\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.571397\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.538909\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.545614\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.553522\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.550556\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.557610\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.548237\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.539463\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.548661\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.539270\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.559679\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.604025\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.563070\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.527952\n",
            "\n",
            "Test set: Average loss: 1.4975, Accuracy: 9641/10000 (96%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.564476\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.550431\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.547192\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 1.528225\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 1.517530\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.547678\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 1.556866\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 1.554330\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.552205\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 1.543705\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.525774\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 1.563735\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 1.517309\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 1.501498\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 1.548289\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.542383\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.521786\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 1.570076\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 1.573071\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 1.545219\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.531768\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 1.548878\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 1.539849\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 1.567053\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.553874\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.532124\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 1.528709\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 1.526093\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 1.512465\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 1.526886\n",
            "\n",
            "Test set: Average loss: 1.4970, Accuracy: 9639/10000 (96%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.564471\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 1.509824\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 1.570922\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 1.521289\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 1.541636\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.547449\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 1.534500\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 1.543033\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.550357\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 1.587976\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.574378\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 1.505724\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.560394\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 1.539879\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.550495\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.519491\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.546930\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 1.537547\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 1.560229\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 1.527323\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.564524\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 1.548273\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 1.528857\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 1.495404\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.515567\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.562110\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 1.533784\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 1.514714\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 1.533874\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 1.539249\n",
            "\n",
            "Test set: Average loss: 1.4939, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.520083\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 1.535388\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 1.543325\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 1.536730\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 1.532497\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.567110\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 1.568775\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 1.493904\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.529608\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 1.544670\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.510179\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 1.499514\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 1.565726\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 1.508020\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 1.525891\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.531411\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.526179\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 1.512773\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 1.524099\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 1.542111\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.553697\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 1.517304\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 1.494946\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 1.548902\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.567996\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.548480\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 1.551292\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 1.515805\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 1.522183\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 1.506613\n",
            "\n",
            "Test set: Average loss: 1.4917, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.531640\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 1.524964\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 1.521100\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 1.524795\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 1.556842\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.519350\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 1.510543\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 1.541510\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.555767\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 1.541040\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.526211\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 1.491385\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 1.569535\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 1.493139\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 1.558816\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.559485\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.519792\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 1.505226\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 1.546756\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 1.543859\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.505303\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 1.586708\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.541524\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 1.511010\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.539278\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.544360\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 1.522528\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 1.515056\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 1.486848\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 1.533383\n",
            "\n",
            "Test set: Average loss: 1.4910, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.508594\n",
            "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 1.534320\n",
            "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 1.545077\n",
            "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 1.535672\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 1.498531\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 1.532272\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 1.539699\n",
            "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 1.521176\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.561985\n",
            "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 1.547815\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 1.529799\n",
            "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 1.559311\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 1.529455\n",
            "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 1.530316\n",
            "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 1.546877\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 1.526315\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.516074\n",
            "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 1.493494\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 1.555440\n",
            "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 1.530701\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 1.527511\n",
            "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 1.532587\n",
            "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 1.518748\n",
            "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 1.508530\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 1.548092\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 1.502791\n",
            "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 1.522923\n",
            "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 1.513114\n",
            "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 1.516525\n",
            "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 1.490357\n",
            "\n",
            "Test set: Average loss: 1.4897, Accuracy: 9717/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "data, target = test_data[1]  # Get one test sample\n",
        "data = data.unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim=1, keepdim=True)\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "# Fix squeeze issue\n",
        "image = data.squeeze().cpu().numpy()  # Ensure correct shape (28,28)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis('off')  # Optional: Hide axes for clarity\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "aQK84ZQzf_jS",
        "outputId": "6a73f8a4-215e-4be8-c730-8c8fe2dbf412"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor([[2]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-9930ebfac668>:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2UxMAW4fgAnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}